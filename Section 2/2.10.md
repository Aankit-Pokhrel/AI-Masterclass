# The Activation Function

There are many types of activation function, we will cover 4

- Threshold Function

  - ![Threshold Activation Function](https://media.geeksforgeeks.org/wp-content/uploads/20210103201821/threshold-300x232.jpg)
  - x-axis weighted sum of inputs
  - y-axis values from 0 to 1
  - if the value is < 0 threshold function passes 0, else output is 1
  - Binary output function

- Sigmoid Function

  - ![Sigmoid Function](https://raw.githubusercontent.com/Codecademy/docs/main/media/sigmoid-function.png)
  - formula:
    - $$\frac{1}{1 + e^{-x}}$$
    - x is the value of the weighted sums
    - it is a smooth function
    - useful in output layer

- Rectifier function

  - ![Rectifier Function](https://nickmccullum.com/images/python-deep-learning/deep-learning-activation-functions/rectifier-function.png)
  - one of the most popular functions in AI NNs

- Hyperbolic Tangent Function (tanh)
  - ![Hyperbolic Tangent Function](https://www.researchgate.net/publication/350103066/figure/fig3/AS:1002064838664197@1615922283547/Tanh-function-Source.png)
  - Formula:
    - $$\frac{1 - e^{-2x}}{1 + e^{-2x}}$$
  - the values can be -1 <= f(z) <= 1

# Exercise

1. If your Dependent variable is binary, which threshold function would you use?
   - Threshold Activation Function
     - Fits perfectly
   - Sigmoid Activation Function
     - could be used as a probability of the output being either 0 or 1, follow basic rounding rules

# Process

1. Inputs are sent into the hidden layer
2. Activation Function Applied in hidden layer
   - this is where the Rectifier function is applied usually
3. Output sent to output layer
4. Activation function is applied in output layer
   - this is where the sigmoid function can be applied
5. Output sent out
